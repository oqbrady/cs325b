{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd1ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from osgeo import gdal\n",
    "import math\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657441dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8430fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_val = -32768.0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3303648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(vh, rows, cols):\n",
    "    \"\"\"\n",
    "    Pad an image to make it divisible by some block_size.\n",
    "    Pad on the right and bottom edges so annotations are still usable.\n",
    "    \"\"\"\n",
    "    r, c = vh.shape\n",
    "    to_rows = math.ceil(r / rows) * rows\n",
    "    to_cols = math.ceil(c / cols) * cols\n",
    "    pad_rows = to_rows - r\n",
    "    pad_cols = to_cols - c\n",
    "    vh_pad = np.pad(\n",
    "        vh, pad_width=((0, pad_rows), (0, pad_cols)), mode=\"constant\", constant_values=0\n",
    "    )\n",
    "    return vh_pad, pad_rows, pad_cols\n",
    "\n",
    "def get_grid_coords(padded_img, chips, grids):\n",
    "    \"\"\"\n",
    "    Obtain grid coordinates for chip origins from padded images\n",
    "    \"\"\"\n",
    "    chip_size = chips[0].shape[0]\n",
    "    grid_coords_y = np.linspace(0, padded_img.shape[0] - chip_size, grids.shape[0])\n",
    "    grid_coords_x = np.linspace(0, padded_img.shape[1] - chip_size, grids.shape[1])\n",
    "    grid_coords = [(int(x), int(y)) for y in grid_coords_y for x in grid_coords_x]\n",
    "    return grid_coords\n",
    "\n",
    "def scene_pixels_to_chip_pixels(chips, grid_coords, scene_rows, scene_cols):\n",
    "    \"\"\"\n",
    "    Convert scene-level pixel indices for detections to chip-level indices\n",
    "    \"\"\"\n",
    "    chip_size = chips[0].shape[0]\n",
    "    chip_rows = (scene_rows) % (chip_size)\n",
    "    chip_cols = (scene_cols) % (chip_size)\n",
    "    chip_ind_row = (scene_rows) // chip_size * chip_size\n",
    "    chip_ind_col = (scene_cols) // chip_size * chip_size\n",
    "    chip_index = [grid_coords.index((c, r)) for c, r in zip(chip_ind_col, chip_ind_row)]\n",
    "    return chip_rows, chip_cols, chip_index, grid_coords\n",
    "\n",
    "def chip_sar_img(input_img, sz):\n",
    "    \"\"\"\n",
    "    Takes a raster from xView3 as input and outputs\n",
    "    a set of chips and the coordinate grid for a\n",
    "    given chip size\n",
    "    Args:\n",
    "        input_img (numpy.array): Input image in np.array form\n",
    "        sz (int): Size of chip (will be sz x sz x # of channlls)\n",
    "    Returns:\n",
    "        images: set of image chips\n",
    "        images_grid: grid coordinates for each chip\n",
    "    \"\"\"\n",
    "    # The input_img is presumed to already be padded\n",
    "    images = view_as_blocks(input_img, (sz, sz))\n",
    "    images_grid = images.reshape(\n",
    "        int(input_img.shape[0] / sz), int(input_img.shape[1] / sz), sz, sz\n",
    "    )\n",
    "    return images, images_grid\n",
    "\n",
    "\n",
    "def view_as_blocks(arr, block_size):\n",
    "    \"\"\"\n",
    "    Break up an image into blocks and return array.\n",
    "    \"\"\"\n",
    "    m, n = arr.shape\n",
    "    M, N = block_size\n",
    "    return arr.reshape(m // M, M, n // N, N).swapaxes(1, 2).reshape(-1, M, N)\n",
    "\n",
    "def chip_coord_to_scene(row_x, row_y, vh_grid, chip_idx):\n",
    "    chip_row = chip_idx // vh_grid.shape[1]\n",
    "    chip_col = chip_idx - (vh_grid.shape[1] * (chip_idx // vh_grid.shape[1]))\n",
    "    return (chip_row * chip_sz) + row_x, (chip_col * chip_sz) + row_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "601f31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 360 ms, total: 2.27 s\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "names = ['bay_mean', 'vh_mean', 'vh_max', 'vv_max', 'vh_min', 'vv_min', 'land', 'NaN', 'label', 'scene', 'chip', 'num']\n",
    "df_gbt = pd.read_csv(\"train_GBT.csv\", names=names[:-3])\n",
    "df_means = df_gbt.copy()\n",
    "min_vh = df_means[df_means['vh_min'] != nan_val]['vh_min'].min()\n",
    "min_vv = df_means[df_means['vv_min'] != nan_val]['vv_min'].min()\n",
    "min_bay = df_means[(df_means['bay_mean'] != nan_val) & (df_means['NaN'] == 0)]['bay_mean'].min()\n",
    "mean_vh = df_means[df_means['NaN'] != 1]['vh_mean'].mean()\n",
    "mean_vv = -15 #df_means[df_means['NaN'] != 1]['vv_mean'].mean()\n",
    "mean_bay = df_means[df_means['NaN'] != 1]['bay_mean'].mean()\n",
    "std_vh = 7.4\n",
    "std_vv = 5.15\n",
    "std_bay = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9278e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "p = pd.read_csv(\"submit_v6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0682de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53575, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146ba4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class drop_nans(object):\n",
    "    def __call__(self, image):\n",
    "        image[0, :, :][image[0, :, :] == -32768.] = min_vh - 10\n",
    "        image[1, :, :][image[1, :, :] == -32768.] = min_vv - 10\n",
    "        image[2, :, :][image[2, :, :] == -32768.] = min_bay - 100\n",
    "        return image\n",
    "\n",
    "class norm(object):\n",
    "    def __call__(self, image):\n",
    "        image[0, :, :] = (image[0, :, :] - mean_vh) / std_vh\n",
    "        image[1, :, :] = (image[1, :, :] - mean_vv) / std_vv\n",
    "        image[2, :, :] = (image[2, :, :] - mean_bay) / std_bay\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3973402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [drop_nans(),\n",
    "    norm()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219805ae",
   "metadata": {},
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b403843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.Booster()  # init model\n",
    "bst.load_model('gbt_v1.model')  # load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11e9c5",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee13c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_net = models.resnet18()\n",
    "class_net.fc = nn.Linear(in_features=512, out_features=4, bias=True)\n",
    "class_net.load_state_dict(torch.load('saved_models/resnet9.pth'))\n",
    "class_net.to(device)\n",
    "class_net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e38af0",
   "metadata": {},
   "source": [
    "### Jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4b061a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jitter_net = models.resnet18()\n",
    "jitter_net.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "jitter_net.load_state_dict(torch.load('saved_models/resnet_jitter_9.pth'))\n",
    "jitter_net.to(device)\n",
    "jitter_net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0cf6a",
   "metadata": {},
   "source": [
    "### Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "499a2f36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_net = models.resnet18()\n",
    "length_net.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "length_net.load_state_dict(torch.load('saved_models/resnet_length_v2_11.pth'))\n",
    "length_net.to(device)\n",
    "length_net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821015ea",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "- Load up a scene\n",
    "    -Chip, store chips and labels on disk (!!)\n",
    "    -Re-chip and (attempt) to store chips and labels on disk (!!)\n",
    "       -iterate through small chips\n",
    "           -store means an all vals for scene\n",
    "           -Run through the GBT and identify candidate scence\n",
    "           -Put those through first nerual net\n",
    "               -store class and discard no detection\n",
    "               -estimate length and jitter coords\n",
    "               -put in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923745e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_sz = 50\n",
    "base = '/home/oqbrady/data/data/public/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▎                                                                                  | 9/150 [13:19<3:27:22, 88.24s/it]"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "data_list = os.listdir('/home/oqbrady/data/data/public')\n",
    "for scene in tqdm(data_list):\n",
    "    vh = scene + '/' + 'VH_dB.tif'\n",
    "    vv = scene + '/' + 'VV_dB.tif'\n",
    "    bay = scene + '/' + 'bathymetry.tif'\n",
    "    vh = rasterio.open(base + vh)\n",
    "    vh = vh.read(1)\n",
    "    vv = rasterio.open(base + vv)\n",
    "    vv = vv.read(1)\n",
    "    bay = rasterio.open(base + bay)\n",
    "    bay = bay.read(\n",
    "            out_shape=(\n",
    "                vh.shape[0],\n",
    "                vh.shape[1],\n",
    "            ),\n",
    "            resampling=Resampling.bilinear,\n",
    "        ).squeeze()\n",
    "    vh, _, _ = pad(vh, chip_sz, chip_sz)\n",
    "    vv, _, _ = pad(vv, chip_sz, chip_sz)\n",
    "    bay, _, _ = pad(bay, chip_sz, chip_sz)\n",
    "    vh, vh_grid = chip_sar_img(vh, chip_sz)\n",
    "    vv, vv_grid = chip_sar_img(vv, chip_sz)\n",
    "    bay, bay_grid = chip_sar_img(bay, chip_sz)\n",
    "    bay_mean_tot = []\n",
    "    vh_mean_tot = []\n",
    "    vh_max_tot = []\n",
    "    vv_max_tot = []\n",
    "    vh_min_tot = []\n",
    "    vv_min_tot = []\n",
    "    land_tot = []\n",
    "    nan_tot = []\n",
    "    for idx in range(vh.shape[0]):\n",
    "        bay_mean_tot.append(np.mean(bay[idx]))\n",
    "        vh_mean_tot.append(np.mean(vh[idx]))\n",
    "        vh_max_tot.append(np.max(vh[idx]))\n",
    "        vv_max_tot.append(np.max(vv[idx]))\n",
    "        vh_min_tot.append(np.min(vh[idx]))\n",
    "        vv_min_tot.append(np.min(vv[idx]))\n",
    "        index = np.where(bay[idx] >= 0)\n",
    "        index1 = np.where(vh[idx] == -32768.0)\n",
    "        if (len(index[0]) > 0):\n",
    "            land = 1\n",
    "        else:\n",
    "            land = 0\n",
    "        if (len(index1[0]) > 0):\n",
    "            nan = 1\n",
    "        else:\n",
    "            nan = 0\n",
    "        land_tot.append(land)\n",
    "        nan_tot.append(nan)\n",
    "    data = pd.DataFrame({'bay_mean': bay_mean_tot, 'vh_mean' : vh_mean_tot, 'vh_max' : vh_max_tot, \n",
    "                        'vv_max' : vv_max_tot, 'vh_min' : vh_min_tot, 'vv_min' : vv_min_tot, 'land' : land_tot,\n",
    "                        'NaN' : nan_tot})\n",
    "    dtest = xgb.DMatrix(data)\n",
    "    ypred = bst.predict(dtest)\n",
    "    ypred_bool = ypred > 0.5\n",
    "    data['preds'] = ypred_bool\n",
    "    for i in (data[data['preds']]).index:\n",
    "        image = np.array((vh[i], vv[i], bay[i]))\n",
    "        image = transform(image)\n",
    "        image = torch.from_numpy(image).to(device)\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
    "        class_idx = class_net(image)\n",
    "        pred = torch.argmax(class_idx).item()\n",
    "        if pred != 0:\n",
    "            if pred == 1:\n",
    "                is_vessel = False\n",
    "                is_fishing = False\n",
    "            if pred == 2:\n",
    "                is_vessel = True\n",
    "                is_fishing = False \n",
    "            if pred == 3:\n",
    "                is_vessel = True\n",
    "                is_fishing = True\n",
    "            jitter = jitter_net(image).detach().cpu().numpy()\n",
    "            row = int(25 - jitter.squeeze()[0])\n",
    "            col = int(25 - jitter.squeeze()[1])\n",
    "            scene_row, scene_col = chip_coord_to_scene(row, col, vh_grid, i)\n",
    "            length = length_net(image).item()\n",
    "            predictions.append([scene, scene_row, scene_col, is_vessel, is_fishing, length])\n",
    "    del vh_grid\n",
    "    del vv_grid\n",
    "    del bay_grid\n",
    "    del vh\n",
    "    del vv\n",
    "    del bay\n",
    "submit_csv = pd.DataFrame(predictions, columns=['scene_id', 'detect_scene_row', 'detect_scene_column', 'is_vessel', \n",
    "                                             'is_fishing', 'vessel_length_m'])\n",
    "submit_csv.to_csv(\"submit_v6.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xview3",
   "language": "python",
   "name": "xview3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
